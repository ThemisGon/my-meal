from pydantic import BaseModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import OllamaLLM
from langchain_core.output_parsers import StrOutputParser
import json
from langchain_core.output_parsers import StrOutputParser
from typing import List

llm = OllamaLLM(model="llama3")

class UserProfile(BaseModel):
    goal: str
    calories_target: int
    allergies: List[str] = []
    preferences: List[str] = []
    time_of_day: str
    plan_scope: str
    activity_level: str

template = ChatPromptTemplate.from_messages([
    ("system", "You are a nutrition assistant that extracts user goals and preferences from the user's input and returns ONLY a JSON object with the following format:\n"
           '{{ "goal": str, "calories_target": int, "allergies": [str], "preferences": [str], "time_of_day": str, "plan_scope": str, "activity_level": str }}'
),
    ("human", "{input}")
])
parser = StrOutputParser()
chain = template | llm | parser

def get_user_profile(user_input: str) -> UserProfile:
    response = chain.invoke({"input": user_input})
    raw_text = response
    print("ğŸ§  RAW LLM OUTPUT:\n", raw_text)

    import re, json

    # Î’ÏÎµÏ‚ Ï„Î¿ JSON block
    match = re.search(r"\{.*\}", raw_text, re.DOTALL)
    if not match:
        print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ JSON:\n", raw_text)
        raise ValueError("Î¤Î¿ LLM Î´ÎµÎ½ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ ÏƒÏ‰ÏƒÏ„ÏŒ JSON")

    json_str = match.group()
    profile_dict = json.loads(json_str)

    # âœ… Î’Î¬Î»Îµ ÎµÎ´Ï Ï„Î¿ Î¼Ï€Î»Î¿Îº ÎµÎ»Î­Î³Ï‡Î¿Ï…:
    required_fields = ["goal", "calories_target", "allergies", "preferences", "time_of_day", "plan_scope", "activity_level"]
    for field in required_fields:
        if field not in profile_dict:
            profile_dict[field] = [] if field in ["allergies", "preferences"] else ""

    # ÎœÎµÏ„Î¬ ÎºÎ¬Î½Îµ parse Î¼Îµ Ï„Î¿ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î­Î½Î¿ dict
    return UserProfile(**profile_dict)
